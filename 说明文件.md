# 如何训练模型？

```python
from ultralytics import YOLO

# Load a model
model = YOLO("yolo11n.pt")

# Train the model
train_results = model.train(
    data="coco8.yaml",  # path to dataset YAML
    epochs=100,  # number of training epochs
    imgsz=640,  # training image size
    device="cpu",  # device to run on, i.e. device=0 or device=0,1,2,3 or device=cpu
)

# Evaluate model performance on the validation set
metrics = model.val()

# Perform object detection on an image
results = model("path/to/image.jpg")
results[0].show()

# Export the model to ONNX format
path = model.export(format="onnx")  # return path to exported model
```

# 模型评价标准

| precision | recall | mAP50 | mAP50-95 |
| --------- | ------ | ----- | -------- |
|           |        |       |          |

在YOLO（You Only Look Once）模型的评估中，`metrics/precision(B)`、`metrics/recall(B)`、`metrics/mAP50(B)`和`metrics/mAP50-95(B)` 是一些常用的评估指标，它们用于衡量模型在检测任务中的性能。这里解释一下它们的含义及计算方法：

1. **Precision（精度）**：
   - 精度是指模型预测为正样本（检测到的物体）中，实际为正样本的比例。
   - 公式为：
     \[
     \text{Precision} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Positives}}
     \]
   - `metrics/precision(B)` 表示YOLO模型在B类上的精度。

2. **Recall（召回率）**：
   - 召回率是指所有真实正样本中，被模型正确检测出来的比例。
   - 公式为：
     \[
     \text{Recall} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Negatives}}
     \]
   - `metrics/recall(B)` 表示YOLO模型在B类上的召回率。

3. **mAP50（平均精度，IoU=0.5）**：
   - mAP (Mean Average Precision) 是检测模型综合性能的一个常用指标。mAP50 是指在 IOU（Intersection over Union）阈值为 0.5 时计算的 mAP。
   - 计算方法：
     1. 首先计算各类别的 AP（Average Precision）。
     2. 对所有类别的 AP 取均值，得到 mAP。
   - `metrics/mAP50(B)` 是在 B 类上的 AP50 值。

4. **mAP50-95（平均精度，IoU=0.5 到 0.95）**：
   - mAP50-95 是在不同 IOU 阈值下的平均精度。它取一系列 IOU 阈值（从 0.5 到 0.95，步长为 0.05），计算每个阈值下的 mAP，再取平均。
   - 这种方法可以更好地评估模型在不同 IOU 标准下的性能。
   - `metrics/mAP50-95(B)` 表示在 B 类上从 IOU=0.5 到 0.95 之间的 mAP 平均值。

### 总结
- `metrics/precision(B)` 和 `metrics/recall(B)` 分别表示 YOLO 在 B 类上的精度和召回率。
- `metrics/mAP50(B)` 是在 B 类上，IOU 阈值为 0.5 时的平均精度。
- `metrics/mAP50-95(B)` 是在 B 类上，从 IOU 0.5 到 0.95（步长 0.05）各个阈值的平均精度。 

这些指标用于综合评估模型的准确性和可靠性，其中 mAP50-95 被认为更能全面反映模型在不同 IoU 阈值下的表现。
